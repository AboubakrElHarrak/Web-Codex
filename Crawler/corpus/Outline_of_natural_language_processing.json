{
    "url": "https://en.wikipedia.org/wiki/Outline_of_natural_language_processing",
    "title": "Outline of natural language processing",
    "table_of_contents": [
        "1 Natural language processing",
        "2 Prerequisite technologies",
        "3 Subfields of natural language processing",
        "4 Related fields",
        "5 Structures used in natural language processing",
        "6 Processes of NLP",
        "6.1 Applications",
        "6.2 Component processes",
        "6.2.1 Component processes of natural language understanding",
        "6.2.2 Component processes of natural language generation",
        "7 History of natural language processing",
        "7.1 Timeline of NLP software",
        "8 General natural language processing concepts",
        "9 Natural language processing tools",
        "9.1 Corpora",
        "9.2 Natural language processing toolkits",
        "9.3 Named entity recognizers",
        "9.4 Translation software",
        "9.5 Other software",
        "9.6 Chatterbots",
        "9.6.1 Classic chatterbots",
        "9.6.2 General chatterbots",
        "9.6.3 Instant messenger chatterbots",
        "10 Natural language processing organizations",
        "10.1 Natural language processing-related conferences",
        "10.2 Companies involved in natural language processing",
        "11 Natural language processing publications",
        "11.1 Books",
        "11.1.1 Book series",
        "11.2 Journals",
        "12 People influential in natural language processing",
        "13 See also",
        "14 References",
        "15 Bibliography",
        "16 External links"
    ],
    "content": [
        {
            "paragraph1": "The following outline is provided as an overview of and topical guide to natural language processing:\n",
            "paragraph2": "Natural language processing – computer activity in which computers are entailed to analyze, understand, alter, or generate natural language.  This includes the automation of any or all linguistic forms, activities, or methods of communication, such as conversation, correspondence, reading, written composition, dictation, publishing, translation, lip reading, and so on.  Natural language processing is also the name of the branch of computer science, artificial intelligence, and linguistics concerned with enabling computers to engage in communication using natural language(s) in all forms, including but not limited to speech, print, writing, and signing.\n"
        },
        {
            "title": "Natural language processing",
            "paragraph1": "Natural language processing can be described as all of the following:\n",
            "ul1": "A field of science – systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe.[1]\nAn applied science – field that applies human knowledge to build or design useful things.\nA field of computer science – scientific and practical approach to computation and its applications.\nA branch of artificial intelligence –  intelligence of machines and robots and the branch of computer science that aims to create it.\nA subfield of computational linguistics –  interdisciplinary field dealing with the statistical or rule-based modeling of natural language from a computational perspective.\nAn application of engineering – science, skill, and profession of acquiring and applying scientific, economic, social, and practical knowledge, in order to design and also build structures, machines, devices, systems, materials and processes.\nAn application of software engineering – application of a systematic, disciplined, quantifiable  approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software.[2][3][4]\nA subfield of computer programming – process of designing, writing, testing, debugging, and maintaining the source code of computer programs. This source code is written in one or more programming languages (such as Java, C++, C#, Python, etc.). The purpose of programming is to create a set of instructions that computers use to perform specific operations or to exhibit desired behaviors.\nA subfield of artificial intelligence programming –\nAn applied science – field that applies human knowledge to build or design useful things.\nA field of computer science – scientific and practical approach to computation and its applications.\nA branch of artificial intelligence –  intelligence of machines and robots and the branch of computer science that aims to create it.\nA subfield of computational linguistics –  interdisciplinary field dealing with the statistical or rule-based modeling of natural language from a computational perspective.\nA field of computer science – scientific and practical approach to computation and its applications.\nA branch of artificial intelligence –  intelligence of machines and robots and the branch of computer science that aims to create it.\nA subfield of computational linguistics –  interdisciplinary field dealing with the statistical or rule-based modeling of natural language from a computational perspective.\nA branch of artificial intelligence –  intelligence of machines and robots and the branch of computer science that aims to create it.\nA subfield of computational linguistics –  interdisciplinary field dealing with the statistical or rule-based modeling of natural language from a computational perspective.\nAn application of engineering – science, skill, and profession of acquiring and applying scientific, economic, social, and practical knowledge, in order to design and also build structures, machines, devices, systems, materials and processes.\nAn application of software engineering – application of a systematic, disciplined, quantifiable  approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software.[2][3][4]\nA subfield of computer programming – process of designing, writing, testing, debugging, and maintaining the source code of computer programs. This source code is written in one or more programming languages (such as Java, C++, C#, Python, etc.). The purpose of programming is to create a set of instructions that computers use to perform specific operations or to exhibit desired behaviors.\nA subfield of artificial intelligence programming –\nAn application of software engineering – application of a systematic, disciplined, quantifiable  approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software.[2][3][4]\nA subfield of computer programming – process of designing, writing, testing, debugging, and maintaining the source code of computer programs. This source code is written in one or more programming languages (such as Java, C++, C#, Python, etc.). The purpose of programming is to create a set of instructions that computers use to perform specific operations or to exhibit desired behaviors.\nA subfield of artificial intelligence programming –\nA subfield of computer programming – process of designing, writing, testing, debugging, and maintaining the source code of computer programs. This source code is written in one or more programming languages (such as Java, C++, C#, Python, etc.). The purpose of programming is to create a set of instructions that computers use to perform specific operations or to exhibit desired behaviors.\nA subfield of artificial intelligence programming –\nA subfield of artificial intelligence programming –\nA type of system – set of interacting or interdependent components forming an integrated whole or a set of elements (often called 'components' ) and relationships which are different from relationships of the set or its elements to other elements or sets.\nA system that includes software –  software is a collection of computer programs and related data that provides the instructions for telling a computer what to do and how to do it. Software refers to one or more computer programs and data held in the storage of the computer. In other words, software is a set of programs, procedures, algorithms and its documentation concerned with the operation of a data processing system.\nA system that includes software –  software is a collection of computer programs and related data that provides the instructions for telling a computer what to do and how to do it. Software refers to one or more computer programs and data held in the storage of the computer. In other words, software is a set of programs, procedures, algorithms and its documentation concerned with the operation of a data processing system.\nA type of technology – making, modification, usage, and knowledge of tools, machines, techniques, crafts, systems, methods of organization, in order to solve a problem, improve a preexisting solution to a problem, achieve a goal, handle an applied input/output relation or perform a specific function. It can also refer to the collection of such tools, machinery, modifications, arrangements and procedures. Technologies significantly affect human as well as other animal species' ability to control and adapt to their natural environments.\nA form of computer technology – computers and their application. NLP makes use of computers, image scanners, microphones, and many types of software programs.\nLanguage technology –  consists of natural language processing (NLP) and computational linguistics (CL) on the one hand, and speech technology on the other. It also includes many application oriented aspects of these. It is often called human language technology (HLT).\nA form of computer technology – computers and their application. NLP makes use of computers, image scanners, microphones, and many types of software programs.\nLanguage technology –  consists of natural language processing (NLP) and computational linguistics (CL) on the one hand, and speech technology on the other. It also includes many application oriented aspects of these. It is often called human language technology (HLT).\nLanguage technology –  consists of natural language processing (NLP) and computational linguistics (CL) on the one hand, and speech technology on the other. It also includes many application oriented aspects of these. It is often called human language technology (HLT).\n"
        },
        {
            "title": "Prerequisite technologies",
            "paragraph1": "The following technologies make natural language processing possible:\n",
            "ul1": "Communication – the activity of a source sending a message to a receiver\nLanguage –\nSpeech –\nWriting –\nComputing –\nComputers –\nComputer programming –\nInformation extraction –\nUser interface –\nSoftware –\nText editing – program used to edit plain text files\nWord processing – piece of software used for composing, editing, formatting, printing documents\nInput devices – pieces of hardware for sending data to a computer to be processed[5]\nComputer keyboard – typewriter style input device whose input is converted into various data depending on the circumstances\nImage scanners –\nLanguage –\nSpeech –\nWriting –\nSpeech –\nWriting –\nComputing –\nComputers –\nComputer programming –\nInformation extraction –\nUser interface –\nSoftware –\nText editing – program used to edit plain text files\nWord processing – piece of software used for composing, editing, formatting, printing documents\nInput devices – pieces of hardware for sending data to a computer to be processed[5]\nComputer keyboard – typewriter style input device whose input is converted into various data depending on the circumstances\nImage scanners –\nComputers –\nComputer programming –\nInformation extraction –\nUser interface –\nInformation extraction –\nUser interface –\nSoftware –\nText editing – program used to edit plain text files\nWord processing – piece of software used for composing, editing, formatting, printing documents\nText editing – program used to edit plain text files\nWord processing – piece of software used for composing, editing, formatting, printing documents\nInput devices – pieces of hardware for sending data to a computer to be processed[5]\nComputer keyboard – typewriter style input device whose input is converted into various data depending on the circumstances\nImage scanners –\nComputer keyboard – typewriter style input device whose input is converted into various data depending on the circumstances\nImage scanners –\n"
        },
        {
            "title": "Subfields of natural language processing",
            "ul1": "Information extraction (IE) – field concerned in general with the extraction of semantic information from text.  This covers tasks such as named entity recognition, coreference resolution, relationship extraction, etc.\nOntology engineering – field that studies the methods and methodologies for building ontologies, which are formal representations of a set of concepts within a domain and the relationships between those concepts.\nSpeech processing – field that covers speech recognition, text-to-speech and related tasks.\nStatistical natural language processing –\nStatistical semantics – a subfield of computational semantics that establishes semantic relations between words to examine their contexts.\nDistributional semantics – a subfield of statistical semantics that examines the semantic relationship of words across a corpora or in large samples of data.\nStatistical semantics – a subfield of computational semantics that establishes semantic relations between words to examine their contexts.\nDistributional semantics – a subfield of statistical semantics that examines the semantic relationship of words across a corpora or in large samples of data.\nDistributional semantics – a subfield of statistical semantics that examines the semantic relationship of words across a corpora or in large samples of data.\n"
        },
        {
            "title": "Related fields",
            "paragraph1": "Natural language processing contributes to, and makes use of (the theories, tools, and methodologies from), the following fields:\n",
            "ul1": "Automated reasoning – area of computer science and mathematical logic dedicated to understanding various aspects of reasoning, and producing software which allows computers to reason completely, or nearly completely, automatically. A sub-field of artificial intelligence, automatic reasoning is also grounded in theoretical computer science and philosophy of mind.\nLinguistics – scientific study of human language. Natural language processing requires understanding of the structure and application of language, and therefore it draws heavily from linguistics.\nApplied linguistics – interdisciplinary field of study that identifies, investigates, and offers solutions to language-related real-life problems. Some of the academic fields related to applied linguistics are education, linguistics, psychology, computer science, anthropology, and sociology. Some of the subfields of applied linguistics relevant to natural language processing are:\nBilingualism / Multilingualism –\nComputer-mediated communication (CMC) – any communicative transaction that occurs through the use of two or more networked computers.[6] Research on CMC focuses largely on the social effects of different computer-supported communication technologies. Many recent studies involve Internet-based social networking supported by social software.\nContrastive linguistics – practice-oriented linguistic approach that seeks to describe the differences and similarities between a pair of languages.\nConversation analysis (CA) – approach to the study of social interaction, embracing both verbal and non-verbal conduct, in situations of everyday life. Turn-taking is one aspect of language use that is studied by CA.\nDiscourse analysis – various approaches to analyzing written, vocal, or sign language use or any significant semiotic event.\nForensic linguistics – application of linguistic knowledge, methods and insights to the forensic context of law, language, crime investigation, trial, and judicial procedure.\nInterlinguistics – study of improving communications between people of different first languages with the use of ethnic and auxiliary languages (lingua franca). For instance by use of intentional international auxiliary languages, such as Esperanto or Interlingua, or spontaneous interlanguages known as pidgin languages.\nLanguage assessment – assessment of first, second or other language in the school, college, or university context; assessment of language use in the workplace; and assessment of language in the immigration, citizenship, and asylum contexts. The assessment may include analyses of listening, speaking, reading, writing or cultural understanding, with respect to understanding how the language works theoretically and the ability to use the language practically.\nLanguage pedagogy – science and art of language education, including approaches and methods of language teaching and study. Natural language processing is used in programs designed to teach language, including first and second language training.\nLanguage planning –\nLanguage policy –\nLexicography –\nLiteracies –\nPragmatics –\nSecond language acquisition –\nStylistics –\nTranslation –\nComputational linguistics –  interdisciplinary field dealing with the statistical or rule-based modeling of natural language from a computational perspective. The models and tools of computational linguistics are used extensively in the field of natural language processing, and vice versa.\nComputational semantics –\nCorpus linguistics – study of language as expressed in samples (corpora) of \"real world\" text.  Corpora is the plural of corpus, and a corpus is a specifically selected collection of texts (or speech segments) composed of natural language. After it is constructed (gathered or composed), a corpus is analyzed with the methods of computational linguistics to infer the meaning and context of its components (words, phrases, and sentences), and the relationships between them.  Optionally, a corpus can be annotated (\"tagged\") with data (manually or automatically) to make the corpus easier to understand (e.g., part-of-speech tagging).  This data is then applied to make sense of user input, for example, to make better (automated) guesses of what people are talking about or saying, perhaps to achieve more narrowly focused web searches, or for speech recognition.\nMetalinguistics –\nSign linguistics – scientific study and analysis of natural sign languages, their features, their structure (phonology, morphology, syntax, and semantics), their acquisition (as a primary or secondary language), how they develop independently of other languages, their application in communication, their relationships to other languages (including spoken languages), and many other aspects.\nApplied linguistics – interdisciplinary field of study that identifies, investigates, and offers solutions to language-related real-life problems. Some of the academic fields related to applied linguistics are education, linguistics, psychology, computer science, anthropology, and sociology. Some of the subfields of applied linguistics relevant to natural language processing are:\nBilingualism / Multilingualism –\nComputer-mediated communication (CMC) – any communicative transaction that occurs through the use of two or more networked computers.[6] Research on CMC focuses largely on the social effects of different computer-supported communication technologies. Many recent studies involve Internet-based social networking supported by social software.\nContrastive linguistics – practice-oriented linguistic approach that seeks to describe the differences and similarities between a pair of languages.\nConversation analysis (CA) – approach to the study of social interaction, embracing both verbal and non-verbal conduct, in situations of everyday life. Turn-taking is one aspect of language use that is studied by CA.\nDiscourse analysis – various approaches to analyzing written, vocal, or sign language use or any significant semiotic event.\nForensic linguistics – application of linguistic knowledge, methods and insights to the forensic context of law, language, crime investigation, trial, and judicial procedure.\nInterlinguistics – study of improving communications between people of different first languages with the use of ethnic and auxiliary languages (lingua franca). For instance by use of intentional international auxiliary languages, such as Esperanto or Interlingua, or spontaneous interlanguages known as pidgin languages.\nLanguage assessment – assessment of first, second or other language in the school, college, or university context; assessment of language use in the workplace; and assessment of language in the immigration, citizenship, and asylum contexts. The assessment may include analyses of listening, speaking, reading, writing or cultural understanding, with respect to understanding how the language works theoretically and the ability to use the language practically.\nLanguage pedagogy – science and art of language education, including approaches and methods of language teaching and study. Natural language processing is used in programs designed to teach language, including first and second language training.\nLanguage planning –\nLanguage policy –\nLexicography –\nLiteracies –\nPragmatics –\nSecond language acquisition –\nStylistics –\nTranslation –\nBilingualism / Multilingualism –\nComputer-mediated communication (CMC) – any communicative transaction that occurs through the use of two or more networked computers.[6] Research on CMC focuses largely on the social effects of different computer-supported communication technologies. Many recent studies involve Internet-based social networking supported by social software.\nContrastive linguistics – practice-oriented linguistic approach that seeks to describe the differences and similarities between a pair of languages.\nConversation analysis (CA) – approach to the study of social interaction, embracing both verbal and non-verbal conduct, in situations of everyday life. Turn-taking is one aspect of language use that is studied by CA.\nDiscourse analysis – various approaches to analyzing written, vocal, or sign language use or any significant semiotic event.\nForensic linguistics – application of linguistic knowledge, methods and insights to the forensic context of law, language, crime investigation, trial, and judicial procedure.\nInterlinguistics – study of improving communications between people of different first languages with the use of ethnic and auxiliary languages (lingua franca). For instance by use of intentional international auxiliary languages, such as Esperanto or Interlingua, or spontaneous interlanguages known as pidgin languages.\nLanguage assessment – assessment of first, second or other language in the school, college, or university context; assessment of language use in the workplace; and assessment of language in the immigration, citizenship, and asylum contexts. The assessment may include analyses of listening, speaking, reading, writing or cultural understanding, with respect to understanding how the language works theoretically and the ability to use the language practically.\nLanguage pedagogy – science and art of language education, including approaches and methods of language teaching and study. Natural language processing is used in programs designed to teach language, including first and second language training.\nLanguage planning –\nLanguage policy –\nLexicography –\nLiteracies –\nPragmatics –\nSecond language acquisition –\nStylistics –\nTranslation –\nComputational linguistics –  interdisciplinary field dealing with the statistical or rule-based modeling of natural language from a computational perspective. The models and tools of computational linguistics are used extensively in the field of natural language processing, and vice versa.\nComputational semantics –\nCorpus linguistics – study of language as expressed in samples (corpora) of \"real world\" text.  Corpora is the plural of corpus, and a corpus is a specifically selected collection of texts (or speech segments) composed of natural language. After it is constructed (gathered or composed), a corpus is analyzed with the methods of computational linguistics to infer the meaning and context of its components (words, phrases, and sentences), and the relationships between them.  Optionally, a corpus can be annotated (\"tagged\") with data (manually or automatically) to make the corpus easier to understand (e.g., part-of-speech tagging).  This data is then applied to make sense of user input, for example, to make better (automated) guesses of what people are talking about or saying, perhaps to achieve more narrowly focused web searches, or for speech recognition.\nComputational semantics –\nCorpus linguistics – study of language as expressed in samples (corpora) of \"real world\" text.  Corpora is the plural of corpus, and a corpus is a specifically selected collection of texts (or speech segments) composed of natural language. After it is constructed (gathered or composed), a corpus is analyzed with the methods of computational linguistics to infer the meaning and context of its components (words, phrases, and sentences), and the relationships between them.  Optionally, a corpus can be annotated (\"tagged\") with data (manually or automatically) to make the corpus easier to understand (e.g., part-of-speech tagging).  This data is then applied to make sense of user input, for example, to make better (automated) guesses of what people are talking about or saying, perhaps to achieve more narrowly focused web searches, or for speech recognition.\nMetalinguistics –\nSign linguistics – scientific study and analysis of natural sign languages, their features, their structure (phonology, morphology, syntax, and semantics), their acquisition (as a primary or secondary language), how they develop independently of other languages, their application in communication, their relationships to other languages (including spoken languages), and many other aspects.\nHuman–computer interaction – the intersection of computer science and behavioral sciences, this field involves the study, planning, and design of the interaction between people (users) and computers.  Attention to human-machine interaction is important, because poorly designed human-machine interfaces can lead to many unexpected problems. A classic example of this is the Three Mile Island accident where investigations concluded that the design of the human–machine interface was at least partially responsible for the disaster.\nInformation retrieval (IR) – field concerned with storing, searching and retrieving information. It is a separate field within computer science (closer to databases), but IR relies on some NLP methods (for example, stemming). Some current research and applications seek to bridge the gap between IR and NLP.\nKnowledge representation (KR) – area of artificial intelligence research aimed at representing knowledge in symbols to facilitate inferencing from those knowledge elements, creating new elements of knowledge. Knowledge Representation research involves analysis of how to reason accurately and effectively and how best to use a set of symbols to represent a set of facts within a knowledge domain.\nSemantic network – study of semantic relations between concepts.\nSemantic Web –\nSemantic network – study of semantic relations between concepts.\nSemantic Web –\nSemantic Web –\nMachine learning – subfield of computer science that examines pattern recognition and computational learning theory in artificial intelligence. There are three broad approaches to machine learning.  Supervised learning occurs when the machine is given example inputs and outputs by a teacher so that it can learn a rule that maps inputs to outputs. Unsupervised learning occurs when the machine determines the inputs structure without being provided example inputs or outputs. Reinforcement learning occurs when a machine must perform a goal without teacher feedback.\nPattern recognition – branch of machine learning that examines how machines recognize regularities in data. As with machine learning, teachers can train machines to recognize patterns by providing them with example inputs and outputs (i.e. Supervised Learning), or the machines can recognize patterns without being trained on any example inputs or outputs (i.e. Unsupervised Learning).\nStatistical classification –\nPattern recognition – branch of machine learning that examines how machines recognize regularities in data. As with machine learning, teachers can train machines to recognize patterns by providing them with example inputs and outputs (i.e. Supervised Learning), or the machines can recognize patterns without being trained on any example inputs or outputs (i.e. Unsupervised Learning).\nStatistical classification –\n"
        },
        {
            "title": "Structures used in natural language processing",
            "ul1": "Anaphora – type of expression whose reference depends upon another referential element. E.g., in the sentence 'Sally preferred the company of herself', 'herself' is an anaphoric expression in that it is coreferential with 'Sally', the sentence's subject.\nContext-free language –\nControlled natural language – a natural language with a restriction introduced on its grammar and vocabulary in order to eliminate ambiguity and complexity\nCorpus – body of data, optionally tagged (for example, through part-of-speech tagging), providing real world samples for analysis and comparison.\nText corpus – large and structured set of texts, nowadays usually electronically stored and processed. They are used to do statistical analysis and hypothesis testing, checking occurrences or validating linguistic rules within a specific subject (or domain).\nSpeech corpus – database of speech audio files and text transcriptions. In Speech technology, speech corpora are used, among other things, to create acoustic models (which can then be used with a speech recognition engine). In Linguistics, spoken corpora are used to do research into phonetic, conversation analysis, dialectology and other fields.\nText corpus – large and structured set of texts, nowadays usually electronically stored and processed. They are used to do statistical analysis and hypothesis testing, checking occurrences or validating linguistic rules within a specific subject (or domain).\nSpeech corpus – database of speech audio files and text transcriptions. In Speech technology, speech corpora are used, among other things, to create acoustic models (which can then be used with a speech recognition engine). In Linguistics, spoken corpora are used to do research into phonetic, conversation analysis, dialectology and other fields.\nGrammar –\nContext-free grammar (CFG) –\nConstraint grammar (CG) –\nDefinite clause grammar (DCG) –\nFunctional unification grammar (FUG) –\nGeneralized phrase structure grammar (GPSG) –\nHead-driven phrase structure grammar (HPSG) –\nLexical functional grammar (LFG) –\nProbabilistic context-free grammar (PCFG) – another name for stochastic context-free grammar.\nStochastic context-free grammar (SCFG) –\nSystemic functional grammar (SFG) –\nTree-adjoining grammar (TAG) –\nContext-free grammar (CFG) –\nConstraint grammar (CG) –\nDefinite clause grammar (DCG) –\nFunctional unification grammar (FUG) –\nGeneralized phrase structure grammar (GPSG) –\nHead-driven phrase structure grammar (HPSG) –\nLexical functional grammar (LFG) –\nProbabilistic context-free grammar (PCFG) – another name for stochastic context-free grammar.\nStochastic context-free grammar (SCFG) –\nSystemic functional grammar (SFG) –\nTree-adjoining grammar (TAG) –\nNatural language –\nn-gram – sequence of n number of tokens, where a \"token\" is a character, syllable, or word. The n is replaced by a number. Therefore, a 5-gram is an n-gram of 5 letters, syllables, or words. \"Eat this\" is a 2-gram (also known as a bigram).\nBigram – n-gram of 2 tokens. Every sequence of 2 adjacent elements in a string of tokens is a bigram. Bigrams are used for speech recognition, they can be used to solve cryptograms, and bigram frequency is one approach to statistical language identification.\nTrigram –  special case of the n-gram, where n is 3.\nBigram – n-gram of 2 tokens. Every sequence of 2 adjacent elements in a string of tokens is a bigram. Bigrams are used for speech recognition, they can be used to solve cryptograms, and bigram frequency is one approach to statistical language identification.\nTrigram –  special case of the n-gram, where n is 3.\nOntology – formal representation of a set of concepts within a domain and the relationships between those concepts.\nTaxonomy – practice and science of classification, including the principles underlying classification, and the methods of classifying things or concepts.\nHyponymy and hypernymy – the linguistics of hyponyms and hypernyms.  A hyponym shares a type-of relationship with its hypernym. For example, pigeon, crow, eagle and seagull are all hyponyms of bird (their hypernym); which, in turn, is a hyponym of animal.\nTaxonomy for search engines – typically called a \"taxonomy of entities\". It is a tree in which nodes are labelled with entities which are expected to occur in a web search query. These trees are used to match keywords from a search query with the keywords from relevant answers (or snippets).\nTaxonomy – practice and science of classification, including the principles underlying classification, and the methods of classifying things or concepts.\nHyponymy and hypernymy – the linguistics of hyponyms and hypernyms.  A hyponym shares a type-of relationship with its hypernym. For example, pigeon, crow, eagle and seagull are all hyponyms of bird (their hypernym); which, in turn, is a hyponym of animal.\nTaxonomy for search engines – typically called a \"taxonomy of entities\". It is a tree in which nodes are labelled with entities which are expected to occur in a web search query. These trees are used to match keywords from a search query with the keywords from relevant answers (or snippets).\nHyponymy and hypernymy – the linguistics of hyponyms and hypernyms.  A hyponym shares a type-of relationship with its hypernym. For example, pigeon, crow, eagle and seagull are all hyponyms of bird (their hypernym); which, in turn, is a hyponym of animal.\nTaxonomy for search engines – typically called a \"taxonomy of entities\". It is a tree in which nodes are labelled with entities which are expected to occur in a web search query. These trees are used to match keywords from a search query with the keywords from relevant answers (or snippets).\nTextual entailment – directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. In the TE framework, the entailing and entailed texts are termed text (t) and hypothesis (h), respectively. The relation is directional because even if \"t entails h\", the reverse \"h entails t\" is much less certain.\nTriphone – sequence of three phonemes. Triphones are useful in models of natural language processing where they are used to establish the various contexts in which a phoneme can occur in a particular natural language.\n"
        },
        {
            "title": "Processes of NLP",
            "subtitle1": "Applications",
            "ul1": "Automated essay scoring (AES) – the use of specialized computer programs to assign grades to essays written in an educational setting. It is a method of educational assessment and an application of natural language processing. Its objective is to classify a large set of textual entities into a small number of discrete categories, corresponding to the possible grades—for example, the numbers 1 to 6. Therefore, it can be considered a problem of statistical classification.\nAutomatic image annotation – process by which a computer system automatically assigns textual metadata in the form of captioning or keywords to a digital image. The annotations are used in image retrieval systems to organize and locate images of interest from a database.\nAutomatic summarization – process of reducing a text document with a computer program in order to create a summary that retains the most important points of the original document. Often used to provide summaries of text of a known type, such as articles in the financial section of a newspaper.\nTypes\nKeyphrase extraction –\nDocument summarization –\nMulti-document summarization –\nMethods and techniques\nExtraction-based summarization –\nAbstraction-based summarization –\nMaximum entropy-based summarization –\nSentence extraction –\nAided summarization –\nHuman aided machine summarization (HAMS) –\nMachine aided human summarization (MAHS) –\nTypes\nKeyphrase extraction –\nDocument summarization –\nMulti-document summarization –\nKeyphrase extraction –\nDocument summarization –\nMulti-document summarization –\nMulti-document summarization –\nMethods and techniques\nExtraction-based summarization –\nAbstraction-based summarization –\nMaximum entropy-based summarization –\nSentence extraction –\nAided summarization –\nHuman aided machine summarization (HAMS) –\nMachine aided human summarization (MAHS) –\nExtraction-based summarization –\nAbstraction-based summarization –\nMaximum entropy-based summarization –\nSentence extraction –\nAided summarization –\nHuman aided machine summarization (HAMS) –\nMachine aided human summarization (MAHS) –\nHuman aided machine summarization (HAMS) –\nMachine aided human summarization (MAHS) –\nAutomatic taxonomy induction – automated construction of tree structures from a corpus. This may be applied to building taxonomical classification systems for reading by end users, such as web directories or subject outlines.\nCoreference resolution – in order to derive the correct interpretation of text, or even to estimate the relative importance of various mentioned subjects, pronouns and other referring expressions need to be connected to the right individuals or objects. Given a sentence or larger chunk of text, coreference resolution determines which words (\"mentions\") refer to which objects (\"entities\") included in the text.\nAnaphora resolution – concerned with matching up pronouns with the nouns or names that they refer to. For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\nAnaphora resolution – concerned with matching up pronouns with the nouns or names that they refer to. For example, in a sentence such as \"He entered John's house through the front door\", \"the front door\" is a referring expression and the bridging relationship to be identified is the fact that the door being referred to is the front door of John's house (rather than of some other structure that might also be referred to).\nDialog system –\nForeign-language reading aid – computer program that assists a non-native language user to read properly in their target language. The proper reading means that the pronunciation should be correct and stress to different parts of the words should be proper.\nForeign language writing aid – computer program or any other instrument that assists a non-native language user (also referred to as a foreign language learner) in writing decently in their target language. Assistive operations can be classified into two categories: on-the-fly prompts and post-writing checks.\nGrammar checking – the act of verifying the grammatical correctness of written text, especially if this act is performed by a computer program.\nInformation retrieval –\nCross-language information retrieval –\nCross-language information retrieval –\nMachine translation (MT) – aims to automatically translate text from one human language to another.  This is one of the most difficult problems, and is a member of a class of problems colloquially termed \"AI-complete\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) in order to solve properly.\nClassical approach of machine translation – rules-based machine translation.\nComputer-assisted translation –\nInteractive machine translation –\nTranslation memory – database that stores so-called \"segments\", which can be sentences, paragraphs or sentence-like units (headings, titles or elements in a list) that have previously been translated, in order to aid human translators.\nExample-based machine translation –\nRule-based machine translation –\nClassical approach of machine translation – rules-based machine translation.\nComputer-assisted translation –\nInteractive machine translation –\nTranslation memory – database that stores so-called \"segments\", which can be sentences, paragraphs or sentence-like units (headings, titles or elements in a list) that have previously been translated, in order to aid human translators.\nInteractive machine translation –\nTranslation memory – database that stores so-called \"segments\", which can be sentences, paragraphs or sentence-like units (headings, titles or elements in a list) that have previously been translated, in order to aid human translators.\nExample-based machine translation –\nRule-based machine translation –\nNatural language programming – interpreting and compiling instructions communicated in natural language into computer instructions (machine code).\nNatural language search –\nOptical character recognition (OCR) – given an image representing printed text, determine the corresponding text.\nQuestion answering – given a human-language question, determine its answer.  Typical questions have a specific right answer (such as \"What is the capital of Canada?\"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\").\nOpen domain question answering –\nOpen domain question answering –\nSpam filtering –\nSentiment analysis – extracts subjective information usually from a set of documents, often using online reviews to determine \"polarity\" about specific objects. It is especially useful for identifying trends of public opinion in the social media, for the purpose of marketing.\nSpeech recognition – given a sound clip of a person or people speaking, determine the textual representation of the speech.  This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed \"AI-complete\" (see above).  In natural speech there are hardly any pauses between successive words, and thus speech segmentation is a necessary subtask of speech recognition (see below). In most spoken languages, the sounds representing successive letters blend into each other in a process termed coarticulation, so the conversion of the analog signal to discrete characters can be a very difficult process.\nSpeech synthesis (Text-to-speech) –\nText-proofing –\nText simplification – automated editing a document to include fewer words, or use easier words, while retaining its underlying meaning and information.\n",
            "subtitle2": "Component processes",
            "ul2": "Natural language understanding – converts chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural languages concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural languages semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization.[7]\nNatural language generation – task of converting information from computer databases into readable  human language.\n",
            "ul3": "Automatic document classification (text categorization) –\nAutomatic language identification –\nAutomatic language identification –\nCompound term processing – category of techniques that identify compound terms and match them to their definitions. Compound terms are built by combining two (or more) simple terms, for example \"triple\" is a single word term but \"triple heart bypass\" is a compound term.\nAutomatic taxonomy induction –\nCorpus processing –\nAutomatic acquisition of lexicon –\nText normalization –\nText simplification –\nAutomatic acquisition of lexicon –\nText normalization –\nText simplification –\nDeep linguistic processing –\nDiscourse analysis – includes a number of related tasks.  One task is identifying the discourse structure of connected text, i.e. the nature of the discourse relationships between sentences (e.g. elaboration, explanation, contrast).  Another possible task is recognizing and classifying the speech acts in a chunk of text (e.g. yes-no questions, content questions, statements, assertions, orders, suggestions, etc.).\nInformation extraction –\nText mining – process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.\nBiomedical text mining –  (also known as BioNLP), this is text mining applied to texts and literature of the biomedical and molecular biology domain. It is a rather recent research field drawing elements from natural language processing, bioinformatics, medical informatics and computational linguistics. There is an increasing interest in text mining and information extraction strategies applied to the biomedical and molecular biology literature due to the increasing number of electronically available publications stored in databases such as PubMed.\nDecision tree learning –\nSentence extraction –\nTerminology extraction –\nText mining – process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.\nBiomedical text mining –  (also known as BioNLP), this is text mining applied to texts and literature of the biomedical and molecular biology domain. It is a rather recent research field drawing elements from natural language processing, bioinformatics, medical informatics and computational linguistics. There is an increasing interest in text mining and information extraction strategies applied to the biomedical and molecular biology literature due to the increasing number of electronically available publications stored in databases such as PubMed.\nDecision tree learning –\nSentence extraction –\nBiomedical text mining –  (also known as BioNLP), this is text mining applied to texts and literature of the biomedical and molecular biology domain. It is a rather recent research field drawing elements from natural language processing, bioinformatics, medical informatics and computational linguistics. There is an increasing interest in text mining and information extraction strategies applied to the biomedical and molecular biology literature due to the increasing number of electronically available publications stored in databases such as PubMed.\nDecision tree learning –\nSentence extraction –\nTerminology extraction –\nLatent semantic indexing –\nLemmatisation – groups together all like terms that share a same lemma such that they are classified as a single item.\nMorphological segmentation – separates words into individual morphemes and identifies the class of the morphemes.  The difficulty of this task depends greatly on the complexity of the morphology (i.e. the structure of words) of the language being considered.  English has fairly simple morphology, especially inflectional morphology, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g. \"open, opens, opened, opening\") as separate words.  In languages such as Turkish, however, such an approach is not possible, as each dictionary entry has thousands of possible word forms.\nNamed entity recognition (NER) – given a stream of text, determines which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization).  Although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity, and in any case is often inaccurate or insufficient.  For example, the first word of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized.  Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names.  For example, German capitalizes all nouns, regardless of whether they refer to names, and French and Spanish do not capitalize names that serve as adjectives.\nOntology learning –  automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between those concepts from a corpus of natural language text, and encoding them with an ontology language for easy retrieval. Also called \"ontology extraction\", \"ontology generation\", and \"ontology acquisition\".\nParsing – determines the parse tree (grammatical analysis) of a given sentence.  The grammar for natural languages is ambiguous and typical sentences have multiple possible analyses.  In fact, perhaps surprisingly, for a typical sentence there may be thousands of potential parses (most of which will seem completely nonsensical to a human).\nShallow parsing –\nShallow parsing –\nPart-of-speech tagging – given a sentence, determines the part of speech for each word.  Many words, especially common ones, can serve as multiple parts of speech.  For example, \"book\" can be a noun (\"the book on the table\") or verb (\"to book a flight\"); \"set\" can be a noun, verb or adjective; and \"out\" can be any of at least five different parts of speech. Some languages have more such ambiguity than others.  Languages with little inflectional morphology, such as English are particularly prone to such ambiguity. Chinese is prone to such ambiguity because it is a tonal language during verbalization. Such inflection is not readily conveyed via the entities employed within the orthography to convey intended meaning.\nQuery expansion –\nRelationship extraction – given a chunk of text, identifies the relationships among named entities (e.g. who is the wife of whom).\nSemantic analysis (computational) – formal analysis of meaning, and \"computational\" refers to approaches that in principle support effective implementation.\nExplicit semantic analysis –\nLatent semantic analysis –\nSemantic analytics –\nExplicit semantic analysis –\nLatent semantic analysis –\nSemantic analytics –\nSentence breaking (also known as sentence boundary disambiguation and sentence detection) – given a chunk of text, finds the sentence boundaries.  Sentence boundaries are often marked by periods or other punctuation marks, but these same characters can serve other purposes (e.g. marking abbreviations).\nSpeech segmentation – given a sound clip of a person or people speaking, separates it into words.  A subtask of speech recognition and typically grouped with it.\nStemming – reduces an inflected or derived word into its word stem, base, or root form.\nText chunking –\nTokenization – given a chunk of text, separates it into distinct words, symbols, sentences, or other units\nTopic segmentation and recognition – given a chunk of text, separates it into segments each of which is devoted to a topic, and identifies the topic of the segment.\nTruecasing –\nWord segmentation – separates a chunk of continuous text into separate words.  For a language like English, this is fairly trivial, since words are usually separated by spaces.  However, some written languages like Chinese, Japanese and Thai do not mark word boundaries in such a fashion, and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language.\nWord sense disambiguation (WSD) – because many words have more than one meaning, word sense disambiguation is used to select the meaning which makes the most sense in context.  For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or from an online resource such as WordNet.\nWord-sense induction – open problem of natural language processing, which concerns the automatic identification of the senses of a word (i.e. meanings). Given that the output of word-sense induction is a set of senses for the target word (sense inventory), this task is strictly related to that of word-sense disambiguation (WSD), which relies on a predefined sense inventory and aims to solve the ambiguity of words in context.\nAutomatic acquisition of sense-tagged corpora –\nWord-sense induction – open problem of natural language processing, which concerns the automatic identification of the senses of a word (i.e. meanings). Given that the output of word-sense induction is a set of senses for the target word (sense inventory), this task is strictly related to that of word-sense disambiguation (WSD), which relies on a predefined sense inventory and aims to solve the ambiguity of words in context.\nAutomatic acquisition of sense-tagged corpora –\nW-shingling – set of unique \"shingles\"—contiguous subsequences of tokens in a document—that can be used to gauge the similarity of two documents. The w denotes the number of tokens in each shingle in the set.\n",
            "paragraph1": "Natural language generation – task of converting information from computer databases into readable  human language.\n",
            "ul4": "Automatic taxonomy induction (ATI) – automated building of tree structures from a corpus. While ATI is used to construct the core of ontologies (and doing so makes it a component process of natural language understanding), when the ontologies being constructed are end user readable (such as a subject outline), and these are used for the construction of further documentation (such as using an outline as the basis to construct a report or treatise) this also becomes a component process of natural language generation.\nDocument structuring –\n"
        },
        {
            "title": "History of natural language processing",
            "paragraph1": "History of natural language processing\n",
            "ul1": "History of machine translation\nHistory of automated essay scoring\nHistory of natural language user interface\nHistory of natural language understanding\nHistory of optical character recognition\nHistory of question answering\nHistory of speech synthesis\nTuring test – test of a machine's ability to exhibit intelligent behavior, equivalent to or indistinguishable from, that of an actual human. In the original illustrative example, a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being. All participants are separated from one another. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test. The test was introduced by Alan Turing in his 1950 paper \"Computing Machinery and Intelligence,\" which opens with the words: \"I propose to consider the question, 'Can machines think?'\"\nUniversal grammar – theory in linguistics, usually credited to Noam Chomsky, proposing that the ability to learn grammar is hard-wired into the brain.[8] The theory suggests that linguistic ability manifests itself without being taught (see poverty of the stimulus), and that there are properties that all natural human languages share. It is a matter of observation and experimentation to determine precisely what abilities are innate and what properties are shared by all languages.\nALPAC – was a committee of seven scientists led by John R. Pierce, established in 1964 by the U. S. Government in order to evaluate the progress in computational linguistics in general and machine translation in particular. Its report, issued in 1966, gained notoriety for being very skeptical of research done in machine translation so far, and emphasizing the need for basic research in computational linguistics; this eventually caused the U. S. Government to reduce its funding of the topic dramatically.\nConceptual dependency theory – a model of natural language understanding used in artificial intelligence systems.  Roger Schank at Stanford University introduced the model in 1969, in the early days of artificial intelligence.[9] This model was extensively used by Schank's students at Yale University such as Robert Wilensky, Wendy Lehnert, and Janet Kolodner.\nAugmented transition network – type of graph theoretic structure used in the operational definition of formal languages, used especially in parsing relatively complex natural languages, and having wide application in artificial intelligence.  Introduced by William A. Woods in 1970.\nDistributed Language Translation (project) –\n",
            "subtitle1": "Timeline of NLP software"
        },
        {
            "title": "General natural language processing concepts",
            "ul1": "Sukhotin's algorithm – statistical classification algorithm for classifying characters in a text as vowels or consonants. It was initially created by Boris V. Sukhotin.\nT9 (predictive text) – stands for \"Text on 9 keys\", is a USA-patented predictive text technology for mobile phones (specifically those that contain a 3x4 numeric keypad), originally developed by Tegic Communications, now part of Nuance Communications.\nTatoeba – free collaborative online database of example sentences geared towards foreign language learners.\nTeragram Corporation –  fully owned subsidiary of SAS Institute, a major producer of statistical analysis software, headquartered in Cary, North Carolina, USA. Teragram is based in Cambridge, Massachusetts and specializes in the application of computational linguistics to multilingual natural language processing.\nTipTop Technologies – company that developed TipTop Search, a real-time web, social search engine with a unique platform for semantic analysis of natural language. TipTop Search provides results capturing individual and group sentiment, opinions, and experiences from content of various sorts including real-time messages from Twitter or consumer product reviews on Amazon.com.\nTransderivational search – when a search is being conducted for a fuzzy match across a broad field. In computing the equivalent function can be performed using content-addressable memory.\nVocabulary mismatch – common phenomenon in the usage of natural languages, occurring when different people name the same thing or concept differently.\nLRE Map –\nReification (linguistics) –\nSemantic Web –\nMetadata –\nMetadata –\nSpoken dialogue system –\nAffix grammar over a finite lattice –\nAggregation (linguistics) –\nBag-of-words model – model that represents a text as a bag (multiset) of its words that disregards grammar and word sequence, but maintains multiplicity. This model is a commonly used to train document classifiers\nBrill tagger –\nCache language model –\nChaSen, MeCab – provide morphological analysis and word splitting for Japanese\nClassic monolingual WSD –\nClearForest –\nCMU Pronouncing Dictionary – also known as cmudict, is a public domain pronouncing dictionary designed for uses in speech technology, and was created by Carnegie Mellon University (CMU). It defines a mapping from English words to their North American pronunciations, and is commonly used in speech processing applications such as the Festival Speech Synthesis System and the CMU Sphinx speech recognition system.\nConcept mining –\nContent determination –\nDATR –\nDBpedia Spotlight –\nDeep linguistic processing –\nDiscourse relation –\nDocument-term matrix –\nDragomir R. Radev –\nETBLAST –\nFiltered-popping recursive transition network –\nRobby Garner –\nGeneRIF –\nGorn address –\nGrammar induction –\nGrammatik –\nHashing-Trick –\nHidden Markov model –\nHuman language technology –\nInformation extraction –\nInternational Conference on Language Resources and Evaluation –\nKleene star –\nLanguage Computer Corporation –\nLanguage model –\nLanguageware –\nLatent semantic mapping –\nLegal information retrieval –\nLesk algorithm –\nLessac Technologies –\nLexalytics –\nLexical choice –\nLexical Markup Framework –\nLexical substitution –\nLKB –\nLogic form –\nLRE Map –\nMachine translation software usability –\nMAREC –\nMaximum entropy –\nMessage Understanding Conference –\nMETEOR –\nMinimal recursion semantics –\nMorphological pattern –\nMulti-document summarization –\nMultilingual notation –\nNaive semantics –\nNatural language –\nNatural language interface –\nNatural language user interface –\nNews analytics –\nNondeterministic polynomial –\nOpen domain question answering –\nOptimality theory –\nPaco Nathan –\nPhrase structure grammar –\nPowerset (company) –\nProduction (computer science) –\nPropBank –\nQuestion answering –\nRealization (linguistics) –\nRecursive transition network –\nReferring expression generation –\nRewrite rule –\nSemantic compression –\nSemantic neural network –\nSemEval –\nSPL notation –\nStemming – reduces an inflected or derived word into its word stem, base, or root form.\nString kernel –\n"
        },
        {
            "title": "Natural language processing tools",
            "ul1": "Google Ngram Viewer – graphs n-gram usage from a corpus of more than 5.2 million books\n",
            "subtitle1": "Corpora",
            "ul2": "Text corpus (see list) – large and structured set of texts (nowadays usually electronically stored and processed). They are used to do statistical analysis and hypothesis testing, checking occurrences or validating linguistic rules within a specific language territory.\nBank of English\nBritish National Corpus\nCorpus of Contemporary American English (COCA)\nOxford English Corpus\nBank of English\nBritish National Corpus\nCorpus of Contemporary American English (COCA)\nOxford English Corpus\n",
            "subtitle2": "Natural language processing toolkits",
            "paragraph1": "The following natural language processing toolkits are notable collections of natural language processing software. They are suites of libraries, frameworks, and applications for symbolic, statistical natural language and speech processing.\n",
            "subtitle3": "Named entity recognizers",
            "ul3": "ABNER (A Biomedical Named Entity Recognizer) – open source text mining program that uses linear-chain conditional random field sequence models. It automatically tags genes, proteins and other entity names in text. Written by Burr Settles of the University of Wisconsin-Madison.\nStanford NER (Named Entity Recognizer) — Java implementation of a Named Entity Recognizer that uses linear-chain conditional random field sequence models. It automatically tags persons, organizations, and locations in text in English, German, Chinese, and Spanish languages. Written by Jenny Finkel and other members of the Stanford NLP Group at Stanford University.\n",
            "subtitle4": "Translation software",
            "ul4": "Comparison of machine translation applications\nMachine translation applications\nGoogle Translate\nDeepL\nLinguee – web service that provides an online dictionary for a number of language pairs. Unlike similar services, such as LEO, Linguee incorporates a search engine that provides access to large amounts of bilingual, translated sentence pairs, which come from the World Wide Web. As a translation aid, Linguee therefore differs from machine translation services like Babelfish and is more similar in function to a translation memory.\nHindi-to-Punjabi Machine Translation System\nUNL Universal Networking Language\nYahoo! Babel Fish\nReverso\nGoogle Translate\nDeepL\nLinguee – web service that provides an online dictionary for a number of language pairs. Unlike similar services, such as LEO, Linguee incorporates a search engine that provides access to large amounts of bilingual, translated sentence pairs, which come from the World Wide Web. As a translation aid, Linguee therefore differs from machine translation services like Babelfish and is more similar in function to a translation memory.\nHindi-to-Punjabi Machine Translation System\nUNL Universal Networking Language\nYahoo! Babel Fish\nReverso\n",
            "subtitle5": "Other software",
            "ul5": "CTAKES – open-source natural language processing system for information extraction from electronic medical record clinical free-text. It processes clinical notes, identifying types of clinical named entities — drugs, diseases/disorders, signs/symptoms, anatomical sites and procedures. Each named entity has attributes for the text span, the ontology mapping code, context (family history of, current, unrelated to patient), and negated/not negated. Also known as Apache cTAKES.\nDMAP –\nETAP-3 – proprietary linguistic processing system focusing on English and Russian.[12] It is a rule-based system which uses the Meaning-Text Theory as its theoretical foundation.\nJAPE – the Java Annotation Patterns Engine, a component of the open-source General Architecture for Text Engineering (GATE) platform. JAPE is a finite state transducer that operates over annotations based on regular expressions.\nLOLITA – \"Large-scale, Object-based, Linguistic Interactor, Translator and Analyzer\". LOLITA was developed by Roberto Garigliano and colleagues between 1986 and 2000. It was designed as a general-purpose tool for processing unrestricted text that could be the basis of a wide variety of applications. At its core was a semantic network containing some 90,000 interlinked concepts.\nMaluuba –  intelligent personal assistant for Android devices, that uses a contextual approach to search which takes into account the user's geographic location, contacts, and language.\nMETAL MT –  machine translation system developed in the 1980s at the University of Texas and at Siemens which ran on Lisp Machines.\nNever-Ending Language Learning – semantic machine learning system developed by a research team at Carnegie Mellon University, and supported by grants from DARPA, Google, and the NSF, with portions of the system running on a supercomputing cluster provided by Yahoo!.[13] NELL was programmed by its developers to be able to identify a basic set of fundamental semantic relationships between a few hundred predefined categories of data, such as cities, companies, emotions and sports teams. Since the beginning of 2010, the Carnegie Mellon research team has been running NELL around the clock, sifting through hundreds of millions of web pages looking for connections between the information it already knows and what it finds through its search process – to make new connections in a manner that is intended to mimic the way humans learn new information.[14]\nNLTK –\nOnline-translator.com –\nRegulus Grammar Compiler – software system for compiling unification grammars into grammars for speech recognition systems.\nS Voice –\nSiri (software) –\nSpeaktoit –\nTeLQAS –\nWeka's classification tools –\nword2vec – models that were developed by a team of researchers led by Thomas Milkov at Google to generate word embeddings that can reconstruct some of the linguistic context of words using shallow, two dimensional neural nets derived from a much larger vector space.\nFestival Speech Synthesis System –\nCMU Sphinx speech recognition system –\nLanguage Grid - Open source platform for language web services, which can customize language services by combining existing language services.\n",
            "subtitle6": "Chatterbots",
            "paragraph2": "Chatterbot – a text-based conversation agent that can interact with human users through some medium, such as an instant message service. Some chatterbots are designed for specific purposes, while others converse with human users on a wide range of topics.\n",
            "ul6": "Dr. Sbaitso\nELIZA\nPARRY\nRacter (or Claude Chatterbot)\nMark V Shaney\n",
            "ul7": "Albert One - 1998 and 1999 Loebner winner, by Robby Garner.\nA.L.I.C.E. - 2001, 2002, and 2004 Loebner Prize winner developed by Richard Wallace.\nCharlix\nCleverbot (winner of the 2010 Mechanical Intelligence Competition)\nElbot - 2008 Loebner Prize winner, by Fred Roberts.\nEugene Goostman - 2012 Turing 100 winner, by Vladimir Veselov.\nFred - an early chatterbot by Robby Garner.\nJabberwacky\nJeeney AI\nMegaHAL\nMitsuku, 2013 and 2016 Loebner Prize winner[15]\nRose - ... 2015 - 3x Loebner Prize winner, by Bruce Wilcox.\nSimSimi - A popular artificial intelligence conversation program that was created in 2002 by ISMaker.\nSpookitalk - A chatterbot used for NPCs in Douglas Adams' Starship Titanic video game.\nUltra Hal - 2007 Loebner Prize winner, by Robert Medeksza.\nVerbot\n",
            "ul8": "GooglyMinotaur, specializing in Radiohead, the first bot released by ActiveBuddy (June 2001-March 2002)[16]\nSmarterChild, developed by ActiveBuddy and released in June 2001[17]\nInfobot, an assistant on IRC channels such as #perl, primarily to help out with answering Frequently Asked Questions (June 1995-today)[18]\nNegobot, a bot designed to catch online pedophiles by posing as a young girl and attempting to elicit personal details from people it speaks to.[19]\n"
        },
        {
            "title": "Natural language processing organizations",
            "ul1": "AFNLP (Asian Federation of Natural Language Processing Associations) – the organization for coordinating the natural language processing related activities and events in the Asia-Pacific region.\nAustralasian Language Technology Association –\nAssociation for Computational Linguistics – international scientific and professional society for people working on problems involving natural language processing.\n",
            "subtitle1": "Natural language processing-related conferences",
            "ul2": "Annual Meeting of the Association for Computational Linguistics (ACL)\nInternational Conference on Intelligent Text Processing and Computational Linguistics (CICLing)\nInternational Conference on Language Resources and Evaluation – biennial conference organised by the European Language Resources Association with the support of institutions and organisations involved in Natural language processing\nAnnual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)\nText, Speech and Dialogue (TSD) – annual conference\nText Retrieval Conference (TREC) – on-going series of workshops focusing on various information retrieval (IR) research areas, or tracks\n",
            "subtitle2": "Companies involved in natural language processing",
            "ul3": "AlchemyAPI – service provider of a natural language processing API.\nGoogle, Inc. – the Google search engine is an example of automatic summarization, utilizing keyphrase extraction.\nCalais (Reuters product) – provider of a natural language processing services.\nWolfram Research, Inc. developer of natural language processing computation engine Wolfram Alpha.\n"
        },
        {
            "title": "Natural language processing publications",
            "subtitle1": "Books",
            "ul1": "Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing  – Wermter, S., Riloff E. and Scheler, G. (editors).[20] First book that addressed statistical and neural network learning of language.\nSpeech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics – by Daniel Jurafsky and James H. Martin.[21] Introductory book on language technology.\n",
            "ul2": "Studies in Natural Language Processing – book series of the Association for Computational Linguistics, published by Cambridge University Press.\n",
            "subtitle2": "Journals",
            "ul3": "Computational Linguistics – peer-reviewed academic journal in the field of computational linguistics. It is published quarterly by MIT Press for the Association for Computational Linguistics (ACL)\n"
        },
        {
            "title": "People influential in natural language processing",
            "ul1": "Daniel Bobrow –\nRollo Carpenter – creator of Jabberwacky and Cleverbot.\nNoam Chomsky – author of the seminal work Syntactic Structures, which revolutionized Linguistics with 'universal grammar', a rule based system of syntactic structures.[22]\nKenneth Colby –\nDavid Ferrucci – principal investigator of the team that created Watson, IBM's AI computer that won the quiz show Jeopardy!\nLyn Frazier –\nDaniel Jurafsky – Professor of Linguistics and Computer Science at Stanford University. With James H. Martin, he wrote the textbook Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics\nRoger Schank – introduced the conceptual dependency theory for natural language understanding.[23]\nJean E. Fox Tree –\nAlan Turing – originator of the Turing Test.\nJoseph Weizenbaum – author of the ELIZA chatterbot.\nTerry Winograd – professor of computer science at Stanford University, and co-director of the Stanford Human-Computer Interaction Group. He is known within the philosophy of mind and artificial intelligence fields for his work on natural language using the SHRDLU program.\nWilliam Aaron Woods –\nMaurice Gross – author of the concept of local grammar,[24] taking finite automata as the competence model of language.[25]\nStephen Wolfram – CEO and founder of Wolfram Research, creator of the programming language (natural language understanding) Wolfram Language, and natural language processing computation engine Wolfram Alpha.[26]\nVictor Yngve –\n"
        }
    ],
    "links": [
        "https://en.wikipedia.org/wiki/Natural_language_processing",
        "https://en.wikipedia.org/wiki/Natural_language_understanding",
        "https://en.wikipedia.org/wiki/Natural_language_generation",
        "https://en.wikipedia.org/wiki/Natural_language",
        "https://en.wikipedia.org/wiki/Automation",
        "https://en.wikipedia.org/wiki/Conversation",
        "https://en.wikipedia.org/wiki/Publishing",
        "https://en.wikipedia.org/wiki/Translation",
        "https://en.wikipedia.org/wiki/Lip_reading",
        "https://en.wikipedia.org/wiki/Computer_science",
        "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "https://en.wikipedia.org/wiki/Linguistics",
        "https://en.wikipedia.org/wiki/Speech",
        "https://en.wikipedia.org/wiki/Written_language",
        "https://en.wikipedia.org/wiki/Writing",
        "https://en.wikipedia.org/wiki/Sign_language",
        "https://en.wikipedia.org/wiki/Science",
        "https://en.wikipedia.org/wiki/Applied_science",
        "https://en.wikipedia.org/wiki/Computer_science",
        "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "https://en.wikipedia.org/wiki/Computational_linguistics",
        "https://en.wikipedia.org/wiki/Engineering",
        "https://en.wikipedia.org/wiki/Software_engineering",
        "https://en.wikipedia.org/wiki/Computer_programming",
        "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "https://en.wikipedia.org/wiki/System",
        "https://en.wikipedia.org/wiki/Software",
        "https://en.wikipedia.org/wiki/Technology",
        "https://en.wikipedia.org/wiki/Computer_technology",
        "https://en.wikipedia.org/wiki/Language_technology",
        "https://en.wikipedia.org/wiki/Communication",
        "https://en.wikipedia.org/wiki/Language",
        "https://en.wikipedia.org/wiki/Speech",
        "https://en.wikipedia.org/wiki/Writing",
        "https://en.wikipedia.org/wiki/Computing",
        "https://en.wikipedia.org/wiki/Computer",
        "https://en.wikipedia.org/wiki/Computer_programming",
        "https://en.wikipedia.org/wiki/Information_extraction",
        "https://en.wikipedia.org/wiki/User_interface",
        "https://en.wikipedia.org/wiki/Software",
        "https://en.wikipedia.org/wiki/Text_editor",
        "https://en.wikipedia.org/wiki/Text_file",
        "https://en.wikipedia.org/wiki/Word_processor",
        "https://en.wikipedia.org/wiki/Input_device",
        "https://en.wikipedia.org/wiki/Computer_keyboard",
        "https://en.wikipedia.org/wiki/Image_scanner",
        "https://en.wikipedia.org/wiki/Information_extraction",
        "https://en.wikipedia.org/wiki/Named_entity_recognition",
        "https://en.wikipedia.org/wiki/Coreference",
        "https://en.wikipedia.org/wiki/Relationship_extraction",
        "https://en.wikipedia.org/wiki/Ontology_engineering",
        "https://en.wikipedia.org/wiki/Speech_processing",
        "https://en.wikipedia.org/wiki/Speech_recognition",
        "https://en.wikipedia.org/wiki/Statistical_natural_language_processing",
        "https://en.wikipedia.org/wiki/Statistical_semantics",
        "https://en.wikipedia.org/wiki/Computational_semantics",
        "https://en.wikipedia.org/wiki/Distributional_semantics",
        "https://en.wikipedia.org/wiki/Statistical_semantics",
        "https://en.wikipedia.org/wiki/Automated_reasoning",
        "https://en.wikipedia.org/wiki/Linguistics",
        "https://en.wikipedia.org/wiki/Applied_linguistics",
        "https://en.wikipedia.org/wiki/Multilingualism",
        "https://en.wikipedia.org/wiki/Social_networking",
        "https://en.wikipedia.org/wiki/Social_software",
        "https://en.wikipedia.org/wiki/Contrastive_linguistics",
        "https://en.wikipedia.org/wiki/Conversation_analysis",
        "https://en.wikipedia.org/wiki/Discourse_analysis",
        "https://en.wikipedia.org/wiki/Forensic_linguistics",
        "https://en.wikipedia.org/wiki/Interlinguistics",
        "https://en.wikipedia.org/wiki/Language_assessment",
        "https://en.wikipedia.org/wiki/Language_pedagogy",
        "https://en.wikipedia.org/wiki/Language_planning",
        "https://en.wikipedia.org/wiki/Language_policy",
        "https://en.wikipedia.org/wiki/Lexicography",
        "https://en.wikipedia.org/wiki/Literacy",
        "https://en.wikipedia.org/wiki/Pragmatics",
        "https://en.wikipedia.org/wiki/Second_language_acquisition",
        "https://en.wikipedia.org/wiki/Translation",
        "https://en.wikipedia.org/wiki/Computational_linguistics",
        "https://en.wikipedia.org/wiki/Computational_semantics",
        "https://en.wikipedia.org/wiki/Corpus_linguistics",
        "https://en.wikipedia.org/wiki/Metalinguistics",
        "https://en.wikipedia.org/wiki/Three_Mile_Island_accident",
        "https://en.wikipedia.org/wiki/Information_retrieval",
        "https://en.wikipedia.org/wiki/Knowledge_representation",
        "https://en.wikipedia.org/wiki/Semantic_network",
        "https://en.wikipedia.org/wiki/Semantic_Web",
        "https://en.wikipedia.org/wiki/Machine_learning",
        "https://en.wikipedia.org/wiki/Supervised_learning",
        "https://en.wikipedia.org/wiki/Unsupervised_learning",
        "https://en.wikipedia.org/wiki/Reinforcement_learning",
        "https://en.wikipedia.org/wiki/Pattern_recognition",
        "https://en.wikipedia.org/wiki/Machine_learning",
        "https://en.wikipedia.org/wiki/Supervised_learning",
        "https://en.wikipedia.org/wiki/Unsupervised_learning",
        "https://en.wikipedia.org/wiki/Statistical_classification",
        "https://en.wikipedia.org/wiki/Controlled_natural_language",
        "https://en.wikipedia.org/wiki/Text_corpus",
        "https://en.wikipedia.org/wiki/Speech_corpus",
        "https://en.wikipedia.org/wiki/Grammar",
        "https://en.wikipedia.org/wiki/Constraint_grammar",
        "https://en.wikipedia.org/wiki/Definite_clause_grammar",
        "https://en.wikipedia.org/wiki/Generalized_phrase_structure_grammar",
        "https://en.wikipedia.org/wiki/Lexical_functional_grammar",
        "https://en.wikipedia.org/wiki/Systemic_functional_grammar",
        "https://en.wikipedia.org/wiki/Natural_language",
        "https://en.wikipedia.org/wiki/Bigram",
        "https://en.wikipedia.org/wiki/Trigram",
        "https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy",
        "https://en.wikipedia.org/wiki/Taxonomy_for_search_engines",
        "https://en.wikipedia.org/wiki/Tree_structure",
        "https://en.wikipedia.org/wiki/Textual_entailment",
        "https://en.wikipedia.org/wiki/Triphone",
        "https://en.wikipedia.org/wiki/Automated_essay_scoring",
        "https://en.wikipedia.org/wiki/Automatic_image_annotation",
        "https://en.wikipedia.org/wiki/Automatic_summarization",
        "https://en.wikipedia.org/wiki/Sentence_extraction",
        "https://en.wikipedia.org/wiki/Automatic_taxonomy_induction",
        "https://en.wikipedia.org/wiki/Tree_structure",
        "https://en.wikipedia.org/wiki/Anaphora_resolution",
        "https://en.wikipedia.org/wiki/Dialog_system",
        "https://en.wikipedia.org/wiki/Foreign_language_writing_aid",
        "https://en.wikipedia.org/wiki/Grammar_checker",
        "https://en.wikipedia.org/wiki/Computer_program",
        "https://en.wikipedia.org/wiki/Information_retrieval",
        "https://en.wikipedia.org/wiki/Machine_translation",
        "https://en.wikipedia.org/wiki/Interactive_machine_translation",
        "https://en.wikipedia.org/wiki/Translation_memory",
        "https://en.wikipedia.org/wiki/Natural_language_programming",
        "https://en.wikipedia.org/wiki/Natural_language_user_interface",
        "https://en.wikipedia.org/wiki/Optical_character_recognition",
        "https://en.wikipedia.org/wiki/Question_answering",
        "https://en.wikipedia.org/wiki/Open_domain_question_answering",
        "https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering",
        "https://en.wikipedia.org/wiki/Sentiment_analysis",
        "https://en.wikipedia.org/wiki/Speech_recognition",
        "https://en.wikipedia.org/wiki/Text_to_speech",
        "https://en.wikipedia.org/wiki/Natural_speech",
        "https://en.wikipedia.org/wiki/Speech_segmentation",
        "https://en.wikipedia.org/wiki/Coarticulation",
        "https://en.wikipedia.org/wiki/Speech_synthesis",
        "https://en.wikipedia.org/wiki/Text_simplification",
        "https://en.wikipedia.org/wiki/Natural_language_understanding",
        "https://en.wikipedia.org/wiki/Computer",
        "https://en.wikipedia.org/wiki/Natural_language_generation",
        "https://en.wikipedia.org/wiki/Automatic_document_classification",
        "https://en.wikipedia.org/wiki/Automatic_language_identification",
        "https://en.wikipedia.org/wiki/Compound_term_processing",
        "https://en.wikipedia.org/wiki/Automatic_taxonomy_induction",
        "https://en.wikipedia.org/wiki/Automatic_acquisition_of_lexicon",
        "https://en.wikipedia.org/wiki/Text_normalization",
        "https://en.wikipedia.org/wiki/Text_simplification",
        "https://en.wikipedia.org/wiki/Deep_linguistic_processing",
        "https://en.wikipedia.org/wiki/Discourse_analysis",
        "https://en.wikipedia.org/wiki/Discourse",
        "https://en.wikipedia.org/wiki/Speech_act",
        "https://en.wikipedia.org/wiki/Information_extraction",
        "https://en.wikipedia.org/wiki/Text_mining",
        "https://en.wikipedia.org/wiki/Biomedical_text_mining",
        "https://en.wikipedia.org/wiki/Decision_tree_learning",
        "https://en.wikipedia.org/wiki/Sentence_extraction",
        "https://en.wikipedia.org/wiki/Terminology_extraction",
        "https://en.wikipedia.org/wiki/Latent_semantic_indexing",
        "https://en.wikipedia.org/wiki/Lemmatisation",
        "https://en.wikipedia.org/wiki/Morphemes",
        "https://en.wikipedia.org/wiki/English_language",
        "https://en.wikipedia.org/wiki/Inflectional_morphology",
        "https://en.wikipedia.org/wiki/Turkish_language",
        "https://en.wikipedia.org/wiki/Named_entity_recognition",
        "https://en.wikipedia.org/wiki/Capitalization",
        "https://en.wikipedia.org/wiki/Chinese_language",
        "https://en.wikipedia.org/wiki/Arabic_language",
        "https://en.wikipedia.org/wiki/German_language",
        "https://en.wikipedia.org/wiki/Noun",
        "https://en.wikipedia.org/wiki/French_language",
        "https://en.wikipedia.org/wiki/Spanish_language",
        "https://en.wikipedia.org/wiki/Adjective",
        "https://en.wikipedia.org/wiki/Ontology_learning",
        "https://en.wikipedia.org/wiki/Ontology_language",
        "https://en.wikipedia.org/wiki/Parsing",
        "https://en.wikipedia.org/wiki/Parse_tree",
        "https://en.wikipedia.org/wiki/Grammar",
        "https://en.wikipedia.org/wiki/Natural_language",
        "https://en.wikipedia.org/wiki/Ambiguous",
        "https://en.wikipedia.org/wiki/Shallow_parsing",
        "https://en.wikipedia.org/wiki/Part_of_speech",
        "https://en.wikipedia.org/wiki/Parts_of_speech",
        "https://en.wikipedia.org/wiki/Noun",
        "https://en.wikipedia.org/wiki/Verb",
        "https://en.wikipedia.org/wiki/Noun",
        "https://en.wikipedia.org/wiki/Verb",
        "https://en.wikipedia.org/wiki/Adjective",
        "https://en.wikipedia.org/wiki/Inflectional_morphology",
        "https://en.wikipedia.org/wiki/English_language",
        "https://en.wikipedia.org/wiki/Chinese_language",
        "https://en.wikipedia.org/wiki/Tonal_language",
        "https://en.wikipedia.org/wiki/Query_expansion",
        "https://en.wikipedia.org/wiki/Relationship_extraction",
        "https://en.wikipedia.org/wiki/Explicit_semantic_analysis",
        "https://en.wikipedia.org/wiki/Latent_semantic_analysis",
        "https://en.wikipedia.org/wiki/Semantic_analytics",
        "https://en.wikipedia.org/wiki/Sentence_breaking",
        "https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation",
        "https://en.wikipedia.org/wiki/Full_stop",
        "https://en.wikipedia.org/wiki/Punctuation_mark",
        "https://en.wikipedia.org/wiki/Abbreviation",
        "https://en.wikipedia.org/wiki/Speech_segmentation",
        "https://en.wikipedia.org/wiki/Speech_recognition",
        "https://en.wikipedia.org/wiki/Stemming",
        "https://en.wikipedia.org/wiki/Word_stem",
        "https://en.wikipedia.org/wiki/Shallow_parsing",
        "https://en.wikipedia.org/wiki/Topic_segmentation",
        "https://en.wikipedia.org/wiki/Truecasing",
        "https://en.wikipedia.org/wiki/Word_segmentation",
        "https://en.wikipedia.org/wiki/English_language",
        "https://en.wikipedia.org/wiki/Chinese_language",
        "https://en.wikipedia.org/wiki/Japanese_language",
        "https://en.wikipedia.org/wiki/Thai_language",
        "https://en.wikipedia.org/wiki/Vocabulary",
        "https://en.wikipedia.org/wiki/Word_sense_disambiguation",
        "https://en.wikipedia.org/wiki/WordNet",
        "https://en.wikipedia.org/wiki/Natural_language_generation",
        "https://en.wikipedia.org/wiki/Automatic_taxonomy_induction",
        "https://en.wikipedia.org/wiki/Tree_structure",
        "https://en.wikipedia.org/wiki/Document_structuring",
        "https://en.wikipedia.org/wiki/History_of_natural_language_processing",
        "https://en.wikipedia.org/wiki/History_of_machine_translation",
        "https://en.wikipedia.org/wiki/Turing_test",
        "https://en.wikipedia.org/wiki/Universal_grammar",
        "https://en.wikipedia.org/wiki/Linguistics",
        "https://en.wikipedia.org/wiki/Noam_Chomsky",
        "https://en.wikipedia.org/wiki/Poverty_of_the_stimulus",
        "https://en.wikipedia.org/wiki/Human_languages",
        "https://en.wikipedia.org/wiki/ALPAC",
        "https://en.wikipedia.org/wiki/Conceptual_dependency_theory",
        "https://en.wikipedia.org/wiki/Roger_Schank",
        "https://en.wikipedia.org/wiki/Augmented_transition_network",
        "https://en.wikipedia.org/wiki/Distributed_Language_Translation",
        "https://en.wikipedia.org/wiki/Georgetown_University",
        "https://en.wikipedia.org/wiki/IBM",
        "https://en.wikipedia.org/wiki/Daniel_Bobrow",
        "https://en.wikipedia.org/wiki/ELIZA",
        "https://en.wikipedia.org/wiki/Joseph_Weizenbaum",
        "https://en.wikipedia.org/wiki/Rogerian_psychotherapy",
        "https://en.wikipedia.org/wiki/SHRDLU",
        "https://en.wikipedia.org/wiki/Terry_Winograd",
        "https://en.wikipedia.org/wiki/Blocks_world",
        "https://en.wikipedia.org/wiki/PARRY",
        "https://en.wikipedia.org/wiki/Kenneth_Colby",
        "https://en.wikipedia.org/wiki/Chatterbot",
        "https://en.wikipedia.org/wiki/Semantic_networks",
        "https://en.wikipedia.org/wiki/Frame_language",
        "https://en.wikipedia.org/wiki/Roger_Schank",
        "https://en.wikipedia.org/wiki/Robert_Wilensky",
        "https://en.wikipedia.org/wiki/Jabberwacky",
        "https://en.wikipedia.org/wiki/Rollo_Carpenter",
        "https://en.wikipedia.org/wiki/Chatterbot",
        "https://en.wikipedia.org/wiki/Racter",
        "https://en.wikipedia.org/wiki/Chatterbot",
        "https://en.wikipedia.org/wiki/AeroText",
        "https://en.wikipedia.org/wiki/Lockheed_Martin",
        "https://en.wikipedia.org/wiki/IBM",
        "https://en.wikipedia.org/wiki/Microsoft",
        "https://en.wikipedia.org/wiki/Tatoeba",
        "https://en.wikipedia.org/wiki/Teragram_Corporation",
        "https://en.wikipedia.org/wiki/TipTop_Technologies",
        "https://en.wikipedia.org/wiki/Transderivational_search",
        "https://en.wikipedia.org/wiki/Vocabulary_mismatch",
        "https://en.wikipedia.org/wiki/LRE_Map",
        "https://en.wikipedia.org/wiki/Semantic_Web",
        "https://en.wikipedia.org/wiki/Metadata",
        "https://en.wikipedia.org/wiki/Spoken_dialogue_system",
        "https://en.wikipedia.org/wiki/Affix_grammar_over_a_finite_lattice",
        "https://en.wikipedia.org/wiki/Multiset",
        "https://en.wikipedia.org/wiki/Statistical_classification",
        "https://en.wikipedia.org/wiki/Brill_tagger",
        "https://en.wikipedia.org/wiki/Cache_language_model",
        "https://en.wikipedia.org/wiki/ChaSen",
        "https://en.wikipedia.org/wiki/MeCab",
        "https://en.wikipedia.org/wiki/Japanese_language",
        "https://en.wikipedia.org/wiki/Classic_monolingual_WSD",
        "https://en.wikipedia.org/wiki/ClearForest",
        "https://en.wikipedia.org/wiki/CMU_Pronouncing_Dictionary",
        "https://en.wikipedia.org/wiki/Carnegie_Mellon_University",
        "https://en.wikipedia.org/wiki/Festival_Speech_Synthesis_System",
        "https://en.wikipedia.org/wiki/CMU_Sphinx",
        "https://en.wikipedia.org/wiki/Concept_mining",
        "https://en.wikipedia.org/wiki/Content_determination",
        "https://en.wikipedia.org/wiki/DATR",
        "https://en.wikipedia.org/wiki/DBpedia_Spotlight",
        "https://en.wikipedia.org/wiki/Deep_linguistic_processing",
        "https://en.wikipedia.org/wiki/Discourse_relation",
        "https://en.wikipedia.org/wiki/ETBLAST",
        "https://en.wikipedia.org/wiki/Robby_Garner",
        "https://en.wikipedia.org/wiki/GeneRIF",
        "https://en.wikipedia.org/wiki/Gorn_address",
        "https://en.wikipedia.org/wiki/Grammar_induction",
        "https://en.wikipedia.org/wiki/Grammatik",
        "https://en.wikipedia.org/wiki/Hidden_Markov_model",
        "https://en.wikipedia.org/wiki/Human_language_technology",
        "https://en.wikipedia.org/wiki/Information_extraction",
        "https://en.wikipedia.org/wiki/International_Conference_on_Language_Resources_and_Evaluation",
        "https://en.wikipedia.org/wiki/Kleene_star",
        "https://en.wikipedia.org/wiki/Language_Computer_Corporation",
        "https://en.wikipedia.org/wiki/Language_model",
        "https://en.wikipedia.org/wiki/Languageware",
        "https://en.wikipedia.org/wiki/Latent_semantic_mapping",
        "https://en.wikipedia.org/wiki/Legal_information_retrieval",
        "https://en.wikipedia.org/wiki/Lesk_algorithm",
        "https://en.wikipedia.org/wiki/Lessac_Technologies",
        "https://en.wikipedia.org/wiki/Lexalytics",
        "https://en.wikipedia.org/wiki/Lexical_choice",
        "https://en.wikipedia.org/wiki/Lexical_Markup_Framework",
        "https://en.wikipedia.org/wiki/Lexical_substitution",
        "https://en.wikipedia.org/wiki/LKB",
        "https://en.wikipedia.org/wiki/Logic_form",
        "https://en.wikipedia.org/wiki/LRE_Map",
        "https://en.wikipedia.org/wiki/Machine_translation_software_usability",
        "https://en.wikipedia.org/wiki/MAREC",
        "https://en.wikipedia.org/wiki/Principle_of_maximum_entropy",
        "https://en.wikipedia.org/wiki/Message_Understanding_Conference",
        "https://en.wikipedia.org/wiki/METEOR",
        "https://en.wikipedia.org/wiki/Minimal_recursion_semantics",
        "https://en.wikipedia.org/wiki/Morphological_pattern",
        "https://en.wikipedia.org/wiki/Multilingual_notation",
        "https://en.wikipedia.org/wiki/Naive_semantics",
        "https://en.wikipedia.org/wiki/Natural_language",
        "https://en.wikipedia.org/wiki/Natural_language_interface",
        "https://en.wikipedia.org/wiki/Natural_language_user_interface",
        "https://en.wikipedia.org/wiki/News_analytics",
        "https://en.wikipedia.org/wiki/Nondeterministic_polynomial",
        "https://en.wikipedia.org/wiki/Open_domain_question_answering",
        "https://en.wikipedia.org/wiki/Optimality_theory",
        "https://en.wikipedia.org/wiki/Paco_Nathan",
        "https://en.wikipedia.org/wiki/Phrase_structure_grammar",
        "https://en.wikipedia.org/wiki/PropBank",
        "https://en.wikipedia.org/wiki/Question_answering",
        "https://en.wikipedia.org/wiki/Recursive_transition_network",
        "https://en.wikipedia.org/wiki/Referring_expression_generation",
        "https://en.wikipedia.org/wiki/Rewrite_rule",
        "https://en.wikipedia.org/wiki/Semantic_compression",
        "https://en.wikipedia.org/wiki/Semantic_neural_network",
        "https://en.wikipedia.org/wiki/SemEval",
        "https://en.wikipedia.org/wiki/SPL_notation",
        "https://en.wikipedia.org/wiki/Stemming",
        "https://en.wikipedia.org/wiki/Word_stem",
        "https://en.wikipedia.org/wiki/String_kernel",
        "https://en.wikipedia.org/wiki/Google_Ngram_Viewer",
        "https://en.wikipedia.org/wiki/Text_corpus",
        "https://en.wikipedia.org/wiki/List_of_text_corpora",
        "https://en.wikipedia.org/wiki/Bank_of_English",
        "https://en.wikipedia.org/wiki/British_National_Corpus",
        "https://en.wikipedia.org/wiki/Corpus_of_Contemporary_American_English",
        "https://en.wikipedia.org/wiki/Oxford_English_Corpus",
        "https://en.wikipedia.org/wiki/List_of_toolkits",
        "https://en.wikipedia.org/wiki/Natural_language_processing",
        "https://en.wikipedia.org/wiki/Software_framework",
        "https://en.wikipedia.org/wiki/Software_application",
        "https://en.wikipedia.org/wiki/Apertium",
        "https://en.wikipedia.org/wiki/GPL",
        "https://en.wikipedia.org/wiki/ChatScript",
        "https://en.wikipedia.org/wiki/GPL",
        "https://en.wikipedia.org/wiki/Bruce_Wilcox",
        "https://en.wikipedia.org/wiki/Deeplearning4j",
        "https://en.wikipedia.org/wiki/Apache_License",
        "https://en.wikipedia.org/wiki/LISP",
        "https://en.wikipedia.org/wiki/LGPL",
        "https://en.wikipedia.org/wiki/MIT_License",
        "https://en.wikipedia.org/wiki/HPSG",
        "https://en.wikipedia.org/wiki/DKPro",
        "https://en.wikipedia.org/wiki/Apache_License",
        "https://en.wikipedia.org/wiki/General_Architecture_for_Text_Engineering",
        "https://en.wikipedia.org/wiki/LGPL",
        "https://en.wikipedia.org/wiki/Gensim",
        "https://en.wikipedia.org/wiki/LGPL",
        "https://en.wikipedia.org/wiki/LinguaStream",
        "https://en.wikipedia.org/wiki/University_of_Caen",
        "https://en.wikipedia.org/wiki/France",
        "https://en.wikipedia.org/wiki/Common_Public_License",
        "https://en.wikipedia.org/wiki/University_of_Massachusetts_Amherst",
        "https://en.wikipedia.org/wiki/Modular_Audio_Recognition_Framework",
        "https://en.wikipedia.org/wiki/BSD_license",
        "https://en.wikipedia.org/wiki/MontyLingua",
        "https://en.wikipedia.org/wiki/MIT",
        "https://en.wikipedia.org/wiki/Natural_Language_Toolkit",
        "https://en.wikipedia.org/wiki/Apache_License",
        "https://en.wikipedia.org/wiki/OpenNLP",
        "https://en.wikipedia.org/wiki/Apache_Software_Foundation",
        "https://en.wikipedia.org/wiki/SpaCy",
        "https://en.wikipedia.org/wiki/Cython",
        "https://en.wikipedia.org/wiki/MIT_License",
        "https://en.wikipedia.org/wiki/UIMA",
        "https://en.wikipedia.org/wiki/Apache_License",
        "https://en.wikipedia.org/wiki/Apache_Software_Foundation",
        "https://en.wikipedia.org/wiki/Comparison_of_machine_translation_applications",
        "https://en.wikipedia.org/wiki/Google_Translate",
        "https://en.wikipedia.org/wiki/DeepL",
        "https://en.wikipedia.org/wiki/Linguee",
        "https://en.wikipedia.org/wiki/Universal_Networking_Language",
        "https://en.wikipedia.org/wiki/CTAKES",
        "https://en.wikipedia.org/wiki/Digital_Media_Access_Protocol",
        "https://en.wikipedia.org/wiki/LOLITA",
        "https://en.wikipedia.org/wiki/Maluuba",
        "https://en.wikipedia.org/wiki/METAL_MT",
        "https://en.wikipedia.org/wiki/NLTK",
        "https://en.wikipedia.org/wiki/Regulus_Grammar_Compiler",
        "https://en.wikipedia.org/wiki/S_Voice",
        "https://en.wikipedia.org/wiki/Speaktoit",
        "https://en.wikipedia.org/wiki/TeLQAS",
        "https://en.wikipedia.org/wiki/Word2vec",
        "https://en.wikipedia.org/wiki/Festival_Speech_Synthesis_System",
        "https://en.wikipedia.org/wiki/CMU_Sphinx",
        "https://en.wikipedia.org/wiki/Language_Grid",
        "https://en.wikipedia.org/wiki/List_of_chatbots",
        "https://en.wikipedia.org/wiki/Automated_online_assistant",
        "https://en.wikipedia.org/wiki/Chatterbot",
        "https://en.wikipedia.org/wiki/Software_agent",
        "https://en.wikipedia.org/wiki/Instant_message",
        "https://en.wikipedia.org/wiki/ELIZA",
        "https://en.wikipedia.org/wiki/PARRY",
        "https://en.wikipedia.org/wiki/Racter",
        "https://en.wikipedia.org/wiki/Mark_V_Shaney",
        "https://en.wikipedia.org/wiki/Albert_One",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Robby_Garner",
        "https://en.wikipedia.org/wiki/Artificial_Linguistic_Internet_Computer_Entity",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Charlix",
        "https://en.wikipedia.org/wiki/Cleverbot",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Fred_Roberts",
        "https://en.wikipedia.org/wiki/Eugene_Goostman",
        "https://en.wikipedia.org/wiki/Robby_Garner",
        "https://en.wikipedia.org/wiki/Jabberwacky",
        "https://en.wikipedia.org/wiki/Jeeney_AI",
        "https://en.wikipedia.org/wiki/MegaHAL",
        "https://en.wikipedia.org/wiki/Mitsuku",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Bruce_Wilcox",
        "https://en.wikipedia.org/wiki/SimSimi",
        "https://en.wikipedia.org/wiki/Douglas_Adams",
        "https://en.wikipedia.org/wiki/Starship_Titanic",
        "https://en.wikipedia.org/wiki/Ultra_Hal_Assistant",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Verbot",
        "https://en.wikipedia.org/wiki/GooglyMinotaur",
        "https://en.wikipedia.org/wiki/Radiohead",
        "https://en.wikipedia.org/wiki/ActiveBuddy",
        "https://en.wikipedia.org/wiki/SmarterChild",
        "https://en.wikipedia.org/wiki/ActiveBuddy",
        "https://en.wikipedia.org/wiki/Infobot",
        "https://en.wikipedia.org/wiki/Internet_Relay_Chat",
        "https://en.wikipedia.org/wiki/Frequently_Asked_Questions",
        "https://en.wikipedia.org/wiki/Negobot",
        "https://en.wikipedia.org/wiki/AFNLP",
        "https://en.wikipedia.org/wiki/Australasian_Language_Technology_Association",
        "https://en.wikipedia.org/wiki/Association_for_Computational_Linguistics",
        "https://en.wikipedia.org/wiki/Annual_Meeting_of_the_Association_for_Computational_Linguistics",
        "https://en.wikipedia.org/wiki/International_Conference_on_Intelligent_Text_Processing_and_Computational_Linguistics",
        "https://en.wikipedia.org/wiki/International_Conference_on_Language_Resources_and_Evaluation",
        "https://en.wikipedia.org/wiki/Annual_Conference_of_the_North_American_Chapter_of_the_Association_for_Computational_Linguistics",
        "https://en.wikipedia.org/wiki/Text_Retrieval_Conference",
        "https://en.wikipedia.org/wiki/AlchemyAPI",
        "https://en.wikipedia.org/wiki/Wolfram_Alpha",
        "https://en.wikipedia.org/wiki/Daniel_Jurafsky",
        "https://en.wikipedia.org/wiki/Studies_in_Natural_Language_Processing",
        "https://en.wikipedia.org/wiki/Daniel_Bobrow",
        "https://en.wikipedia.org/wiki/Rollo_Carpenter",
        "https://en.wikipedia.org/wiki/Noam_Chomsky",
        "https://en.wikipedia.org/wiki/Syntactic_Structures",
        "https://en.wikipedia.org/wiki/Universal_grammar",
        "https://en.wikipedia.org/wiki/Kenneth_Colby",
        "https://en.wikipedia.org/wiki/David_Ferrucci",
        "https://en.wikipedia.org/wiki/Lyn_Frazier",
        "https://en.wikipedia.org/wiki/Daniel_Jurafsky",
        "https://en.wikipedia.org/wiki/Roger_Schank",
        "https://en.wikipedia.org/wiki/Conceptual_dependency_theory",
        "https://en.wikipedia.org/wiki/Alan_Turing",
        "https://en.wikipedia.org/wiki/Turing_Test",
        "https://en.wikipedia.org/wiki/Joseph_Weizenbaum",
        "https://en.wikipedia.org/wiki/ELIZA",
        "https://en.wikipedia.org/wiki/Chatterbot",
        "https://en.wikipedia.org/wiki/Terry_Winograd",
        "https://en.wikipedia.org/wiki/William_Aaron_Woods",
        "https://en.wikipedia.org/wiki/Maurice_Gross",
        "https://en.wikipedia.org/wiki/Stephen_Wolfram",
        "https://en.wikipedia.org/wiki/Wolfram_Research",
        "https://en.wikipedia.org/wiki/Wolfram_Language",
        "https://en.wikipedia.org/wiki/Wolfram_Alpha",
        "https://en.wikipedia.org/wiki/Victor_Yngve",
        "https://en.wikipedia.org/wiki/Data_mining",
        "https://en.wikipedia.org/wiki/Biomedical_text_mining",
        "https://en.wikipedia.org/wiki/Compound_term_processing",
        "https://en.wikipedia.org/wiki/Controlled_natural_language",
        "https://en.wikipedia.org/wiki/Deep_linguistic_processing",
        "https://en.wikipedia.org/wiki/Foreign_language_reading_aid",
        "https://en.wikipedia.org/wiki/Foreign_language_writing_aid",
        "https://en.wikipedia.org/wiki/Language_technology",
        "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation",
        "https://en.wikipedia.org/wiki/Latent_semantic_indexing",
        "https://en.wikipedia.org/wiki/List_of_natural_language_processing_projects",
        "https://en.wikipedia.org/wiki/LRE_Map",
        "https://en.wikipedia.org/wiki/Natural_language_programming",
        "https://en.wikipedia.org/wiki/Semantic_folding",
        "https://en.wikipedia.org/wiki/Spoken_dialogue_system",
        "https://en.wikipedia.org/wiki/Thought_vector",
        "https://en.wikipedia.org/wiki/Transderivational_search",
        "https://en.wikipedia.org/wiki/Word2vec",
        "https://en.wikipedia.org/wiki/Software_Engineering_Body_of_Knowledge",
        "https://en.wikipedia.org/wiki/IEEE_Computer_Society",
        "https://en.wikipedia.org/wiki/Roger_Schank",
        "https://en.wikipedia.org/wiki/New_York_Times",
        "https://en.wikipedia.org/wiki/Carnegie_Mellon_University",
        "https://en.wikipedia.org/wiki/Roger_Schank",
        "https://en.wikipedia.org/wiki/Daniel_Crevier",
        "https://en.wikipedia.org/wiki/Peter_Norvig",
        "https://en.wikipedia.org/wiki/Outline_of_natural_language_processing",
        "https://en.wikipedia.org/wiki/Outline_of_natural_language_processing",
        "https://en.wikipedia.org/wiki/Main_Page",
        "https://en.wikipedia.org/wiki/Main_Page"
    ]
}