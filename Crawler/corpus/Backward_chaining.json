{
    "url": "https://en.wikipedia.org/wiki/Backward_chaining",
    "title": "Backward chaining",
    "table_of_contents": [
        "1 How it works",
        "2 See also",
        "3 References",
        "4 External links"
    ],
    "content": [
        {
            "paragraph1": "Backward chaining (or backward reasoning) is an inference method described colloquially as working backward from the goal. It is used in automated theorem provers, inference engines, proof assistants, and other artificial intelligence applications.\n",
            "paragraph2": "In game theory, researchers apply it to (simpler) subgames to find a solution to the game, in a process called backward induction. In chess, it is called retrograde analysis, and it is used to generate table bases for chess endgames for computer chess.\n",
            "paragraph3": "Backward chaining is implemented in logic programming by SLD resolution. Both rules are based on the modus ponens inference rule. It is one of the two most commonly used methods of reasoning with inference rules and logical implications – the other is forward chaining. Backward chaining systems usually employ a depth-first search strategy, e.g. Prolog.\n"
        },
        {
            "title": "How it works",
            "paragraph1": "Backward chaining starts with a list of goals (or a hypothesis) and works backwards from the consequent to the antecedent to see if any data supports any of these consequents. An inference engine using backward chaining would search the inference rules until it finds one with a consequent (Then clause) that matches a desired goal. If the antecedent (If clause) of that rule is known to be true, then it is added to the list of goals (for one's goal to be confirmed one must also provide data that confirms this new rule).\n",
            "paragraph2": "For example, suppose a new pet, Fritz, is delivered in an opaque box along with two facts about Fritz:\n",
            "ul1": "Fritz croaks\nFritz eats flies\n",
            "paragraph3": "The goal is to decide whether Fritz is green, based on a rule base containing the following four rules:\n",
            "image1": {
                "url": "//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Backward_Chaining_Frog_Color_Example.png/240px-Backward_Chaining_Frog_Color_Example.png",
                "caption": "\n\t\tAn Example of Backward Chaining.\n\t"
            },
            "ol1": "1 - If X croaks and X eats flies – Then X is a frog\n2 - If X chirps and X sings – Then X is a canary\n3 - If X is a frog – Then X is green\n4 - If X is a canary – Then X is yellow\n",
            "paragraph4": "With backward reasoning, an inference engine can determine whether Fritz is green in four steps.  To start, the query is phrased as a goal assertion that is to be proved: \"Fritz is green\".\n",
            "paragraph5": "1. Fritz is substituted for X in rule #3 to see if its consequent matches the goal, so rule #3 becomes:\n",
            "paragraph6": "Since the consequent matches the goal (\"Fritz is green\"), the rules engine now needs to see if the antecedent (\"Fritz is a frog\") can be proved.  The antecedent, therefore, becomes the new goal:\n",
            "paragraph7": "2. Again substituting Fritz for X, rule #1 becomes:\n",
            "paragraph8": "Since the consequent matches the current goal (\"Fritz is a frog\"), the inference engine now needs to see if the antecedent (\"Fritz croaks and eats flies\") can be proved.  The antecedent, therefore, becomes the new goal:\n",
            "paragraph9": "3. Since this goal is a conjunction of two statements, the inference engine breaks it into two sub-goals, both of which must be proved:\n",
            "paragraph10": "4. To prove both of these sub-goals, the inference engine sees that both of these sub-goals were given as initial facts.  Therefore, the conjunction is true:\n",
            "paragraph11": "therefore the antecedent of rule #1 is true and the consequent must be true:\n",
            "paragraph12": "therefore the antecedent of rule #3 is true and the consequent must be true:\n",
            "paragraph13": "This derivation, therefore, allows the inference engine to prove that Fritz is green.  Rules #2 and #4 were not used.\n",
            "paragraph14": "Note that the goals always match the affirmed versions of the consequents of implications (and not the negated versions as in modus tollens) and even then, their antecedents are then considered as the new goals (and not the conclusions as in affirming the consequent), which ultimately must match known facts (usually defined as consequents whose antecedents are always true); thus, the inference rule used is modus ponens.\n",
            "paragraph15": "Because the list of goals determines which rules are selected and used, this method is called goal-driven, in contrast to data-driven forward-chaining inference. The backward chaining approach is often employed by expert systems.\n",
            "paragraph16": "Programming languages such as Prolog, Knowledge Machine and ECLiPSe support backward chaining within their inference engines.\n"
        }
    ],
    "links": [
        "https://en.wikipedia.org/wiki/Inference",
        "https://en.wikipedia.org/wiki/Automated_theorem_prover",
        "https://en.wikipedia.org/wiki/Inference_engine",
        "https://en.wikipedia.org/wiki/Proof_assistant",
        "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "https://en.wikipedia.org/wiki/Game_theory",
        "https://en.wikipedia.org/wiki/Subgame",
        "https://en.wikipedia.org/wiki/Backward_induction",
        "https://en.wikipedia.org/wiki/Retrograde_analysis",
        "https://en.wikipedia.org/wiki/Chess_endgame",
        "https://en.wikipedia.org/wiki/Computer_chess",
        "https://en.wikipedia.org/wiki/Logic_programming",
        "https://en.wikipedia.org/wiki/SLD_resolution",
        "https://en.wikipedia.org/wiki/Modus_ponens",
        "https://en.wikipedia.org/wiki/Reasoning",
        "https://en.wikipedia.org/wiki/Inference_rule",
        "https://en.wikipedia.org/wiki/Logical_consequence",
        "https://en.wikipedia.org/wiki/Forward_chaining",
        "https://en.wikipedia.org/wiki/Prolog",
        "https://en.wikipedia.org/wiki/Goal",
        "https://en.wikipedia.org/wiki/Hypothesis",
        "https://en.wikipedia.org/wiki/Consequent",
        "https://en.wikipedia.org/wiki/Data",
        "https://en.wikipedia.org/wiki/Inference_engine",
        "https://en.wikipedia.org/wiki/Inference",
        "https://en.wikipedia.org/wiki/Rule_base",
        "https://en.wikipedia.org/wiki/Modus_tollens",
        "https://en.wikipedia.org/wiki/Affirming_the_consequent",
        "https://en.wikipedia.org/wiki/Modus_ponens",
        "https://en.wikipedia.org/wiki/Data_science",
        "https://en.wikipedia.org/wiki/Forward_chaining",
        "https://en.wikipedia.org/wiki/Expert_systems",
        "https://en.wikipedia.org/wiki/Prolog",
        "https://en.wikipedia.org/wiki/Knowledge_Machine",
        "https://en.wikipedia.org/wiki/ECLiPSe",
        "https://en.wikipedia.org/wiki/Backtracking",
        "https://en.wikipedia.org/wiki/Backward_induction",
        "https://en.wikipedia.org/wiki/Forward_chaining",
        "https://en.wikipedia.org/wiki/Opportunistic_reasoning",
        "https://en.wikipedia.org/wiki/Backward_chaining",
        "https://en.wikipedia.org/wiki/Backward_chaining",
        "https://en.wikipedia.org/wiki/Main_Page",
        "https://en.wikipedia.org/wiki/Main_Page"
    ]
}